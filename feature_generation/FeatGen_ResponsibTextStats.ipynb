{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(line):\n",
    "    char_regex = re.compile(r'<[a-z]>')\n",
    "    line = char_regex.sub(' ', str(line).lower())\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(line):\n",
    "    char_regex = re.compile(r'[^а-я]')\n",
    "    line = char_regex.sub(' ', line.lower())\n",
    "    \n",
    "    chkr_ru = SpellChecker(d_ru)\n",
    "    chkr_ru.set_text(line)\n",
    "    mistakes_ru = set([err.word for err in chkr_ru])\n",
    "    \n",
    "    \n",
    "    tokenized = toktok.tokenize(line)\n",
    "    num_mistakes=0\n",
    "    for i in tokenized:\n",
    "        if i in mistakes_ru:\n",
    "            num_mistakes+=1\n",
    "            \n",
    "    num_words = len(line.split(' '))\n",
    "    \n",
    "    mistakes_rate = num_mistakes / num_words\n",
    "            \n",
    "    return mistakes_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep=';')\n",
    "test = pd.read_csv('test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('employment_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923643, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.id.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['id'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>position</th>\n",
       "      <th>employer</th>\n",
       "      <th>achievements</th>\n",
       "      <th>responsibilities</th>\n",
       "      <th>start_date</th>\n",
       "      <th>finish_date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892714</th>\n",
       "      <td>99998.0</td>\n",
       "      <td>Специалист по микрофинансовым операциям</td>\n",
       "      <td>АО \"Вайнемейнен\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;Оформление договоров займа&lt;/li&gt;&lt;li&gt;При...</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>оформлен договор займ при наличн формирован ар...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892715</th>\n",
       "      <td>99999.0</td>\n",
       "      <td>Секретарь</td>\n",
       "      <td>Департамент здравоохранения и социальной помощ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;ol&gt;&lt;li&gt;Ведения делопроизводства, выполнения п...</td>\n",
       "      <td>2006-06-01</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>веден делопроизводств выполнен поручен руковод...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                 position  \\\n",
       "892714  99998.0  Специалист по микрофинансовым операциям   \n",
       "892715  99999.0                                Секретарь   \n",
       "\n",
       "                                                 employer achievements  \\\n",
       "892714                                   АО \"Вайнемейнен\"          NaN   \n",
       "892715  Департамент здравоохранения и социальной помощ...          NaN   \n",
       "\n",
       "                                         responsibilities  start_date  \\\n",
       "892714  <ul><li>Оформление договоров займа</li><li>При...  2016-04-01   \n",
       "892715  <ol><li>Ведения делопроизводства, выполнения п...  2006-06-01   \n",
       "\n",
       "       finish_date                                               text  \n",
       "892714  2020-03-01  оформлен договор займ при наличн формирован ар...  \n",
       "892715  2014-12-01  веден делопроизводств выполнен поручен руковод...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10301"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стат. признаки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# уберем только html тэги\n",
    "data['resp_no_tags'] = data['responsibilities'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "# длина комментария\n",
    "data[\"answer_len\"] = data['resp_no_tags'].apply(len)\n",
    "\n",
    "# кол-во слов с заглавной буквы\n",
    "data['upper_case_word_count'] = data['resp_no_tags'].apply(lambda x: len([wrd for wrd in x.split() if wrd[0].isupper()]))\n",
    "\n",
    "# кол-во знаков препинания\n",
    "data['punctuation_count'] = data['resp_no_tags'].apply(lambda x: len(\"\".join(_ for _ in x if _ in punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_len</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923638</th>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923639</th>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923640</th>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923641</th>\n",
       "      <td>292</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923642</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923643 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        answer_len  upper_case_word_count  punctuation_count\n",
       "0               99                      0                  5\n",
       "1              100                      0                  6\n",
       "2               99                      0                  5\n",
       "3               70                      0                  4\n",
       "4              147                      0                 29\n",
       "...            ...                    ...                ...\n",
       "923638         290                      0                 27\n",
       "923639         119                      0                 11\n",
       "923640         134                      0                  9\n",
       "923641         292                      0                 13\n",
       "923642          80                      0                  6\n",
       "\n",
       "[923643 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['answer_len', 'upper_case_word_count','punctuation_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Определим процент грамматических ошибок\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# import enchant\n",
    "# from enchant.checker import SpellChecker\n",
    "# from nltk.tokenize import ToktokTokenizer\n",
    "\n",
    "# # инициализируем словари\n",
    "# d_ru = enchant.DictWithPWL('ru')\n",
    "\n",
    "# #инициализируем токенайзер\n",
    "# toktok = ToktokTokenizer()\n",
    "\n",
    "# data['resp_grammar_mistakes_per_cent'] = data['resp_no_tags'].apply(spell_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def aggregate_grammar(data):\n",
    "\n",
    "    mean_df = data.groupby(['id'], as_index=False).agg(np.mean)\n",
    "    mean_df.columns = [str(col) + '_mean' if col != 'cluster' else 'cluster' for col in mean_df.columns]\n",
    "    \n",
    "    max_df = data.groupby(['resp_grammar_mistakes_per_cent'], as_index=False).agg(np.max)\n",
    "    max_df.columns = [str(col) + '_max' if col != 'cluster' else 'cluster' for col in max_df.columns]\n",
    "    \n",
    "    min_df = data.groupby(['resp_grammar_mistakes_per_cent'], as_index=False).agg(np.min)\n",
    "    min_df.columns = [str(col) + '_min' if col != 'cluster' else 'cluster' for col in min_df.columns]\n",
    "    \n",
    "    data_frames = [mean_df, max_df, min_df]\n",
    "\n",
    "    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['cluster'], how='right'), data_frames)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_text_feats = data[['id','answer_len', 'upper_case_word_count','punctuation_count']].groupby(['id'], as_index=False).agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((306270, 25), (131259, 24))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_stat = pd.merge(train, stat_text_feats,how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_stat = pd.merge(test, stat_text_feats,how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_stat.fillna(0, inplace=True)\n",
    "test_text_stat.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_stat[['id','answer_len', 'upper_case_word_count','punctuation_count']].to_csv('train_text_stat.csv',index=False)\n",
    "test_text_stat[['id','answer_len', 'upper_case_word_count','punctuation_count']].to_csv('test_text_stat.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
